# -*- coding: utf-8 -*-
"""Water_Potability.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Mx0QjHCqKyPHhabz5Awslmum-evKAnnB
"""

import numpy as np 
import pandas as pd 
import matplotlib.pyplot as plt
#plt.style.use('fivethirtyeight')
#plt.style.use('dark_background')
import seaborn as sns
color = sns.color_palette()
import plotly.express          as ex
import plotly.graph_objs       as go
import plotly.offline          as pyo
import scipy.stats             as stats
#import pymc3                   as pm
#import theano.tensor           as tt
from matplotlib.colors import ListedColormap
from scipy.stats import norm, boxcox
from sklearn.metrics import confusion_matrix, classification_report, accuracy_score
from collections import Counter
from scipy import stats
from tqdm import tqdm_notebook

from sklearn import metrics
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error, confusion_matrix, r2_score, accuracy_score
from sklearn.model_selection import (GridSearchCV, KFold, train_test_split, cross_val_score)

from imblearn.over_sampling import SMOTE
from collections import Counter

from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import GaussianNB
from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier
from sklearn import svm
from xgboost.sklearn import XGBClassifier
from sklearn.tree import DecisionTreeClassifier
# from catboost import CatBoostClassifier

from google.colab import files
uploaded = files.upload()

"""Loading the dataset """

path = "water_potability.csv"
df = pd.read_csv(path)

df.describe()

df[df['Potability']==1].describe()

df[df['Potability']==0].describe()

df.isna().sum().sort_values(ascending=False)

df[df['Sulfate'].isnull()]

phMean_0 = df[df['Potability'] == 0]['ph'].mean(skipna=True)
df.loc[(df['Potability'] == 0) & (df['ph'].isna()), 'ph'] = phMean_0
phMean_1 = df[df['Potability'] == 1]['ph'].mean(skipna=True)
df.loc[(df['Potability'] == 1) & (df['ph'].isna()), 'ph'] = phMean_1

##################################### Imputing 'Sulfate' value #####################################

SulfateMean_0 = df[df['Potability'] == 0]['Sulfate'].mean(skipna=True)
df.loc[(df['Potability'] == 0) & (df['Sulfate'].isna()), 'Sulfate'] = SulfateMean_0
SulfateMean_1 = df[df['Potability'] == 1]['Sulfate'].mean(skipna=True)
df.loc[(df['Potability'] == 1) & (df['Sulfate'].isna()), 'Sulfate'] = SulfateMean_1

################################ Imputing 'Trihalomethanes' value #####################################

TrihalomethanesMean_0 = df[df['Potability'] == 0]['Trihalomethanes'].mean(skipna=True)
df.loc[(df['Potability'] == 0) & (df['Trihalomethanes'].isna()), 'Trihalomethanes'] = TrihalomethanesMean_0
TrihalomethanesMean_1 = df[df['Potability'] == 1]['Trihalomethanes'].mean(skipna=True)
df.loc[(df['Potability'] == 1) & (df['Trihalomethanes'].isna()), 'Trihalomethanes'] = TrihalomethanesMean_1

print('Checking to see any more missing data \n')
df.isna().sum()

# checking the corealtion
plt.figure(figsize=(12,6))
sns.heatmap(df.corr(),annot=True,cmap='RdBu')

fig =  ex.pie (df, names = "Potability", hole = 0.2, )
fig.show ()

df.hist(figsize=(14,14))
plt.show()

"""Skewness"""

def print_skewness(df):
    skewness = df.skew()
    for col, value in skewness.items():
        if value > 0:
            print(f'{col} is positively skewed',value)
        elif value < 0:
            print(f'{col} is negatively skewed',value)
        else:
            print(f'{col} is neutral',value)


print_skewness(df)

sns.pairplot(df,hue='Potability')

# defining function for EDA
def conti_var(x):

    fig, axes = plt.subplots(nrows=1,ncols=4,figsize=(16,5),tight_layout=False)

    axes[0].set_title('Distribution')
    sns.histplot(x,ax=axes[0])
    axes[0].grid()

    axes[1].set_title('Outliers')
    sns.boxplot(x,ax=axes[1])
    axes[1].grid()

    axes[2].set_title('relaation wrt to output variable')
    sns.boxplot(x=df.Potability,y=x,ax=axes[2])
    axes[2].grid()

    sns.distplot(x,ax=axes[3])
    axes[3].grid()
    
plt.show()

df1 = pd.DataFrame(df)

# Calculate the skewness of each column
skewness = df1.skew()

# Iterate over the skewness values and print the skewness type
for col, value in skewness.items():
    if value > 0:
        print(f'{col} is positively skewed----->',value)
    elif value < 0:
        print(f'{col} is negatively skewed----->', value)
    else:
        print(f'{col} is neutral---------------->',value)

#EDA of Ph variable
conti_var(df.ph)
#EDA of Chloramtes
conti_var(df.Chloramines)
#EDA of Hardness variable
conti_var(df.Hardness)
#EDA of solids
conti_var(df.Solids)
#EDA of sulfates
conti_var(df.Sulfate)
#EDA of Conductivity variable
conti_var(df.Conductivity)
# EDA of Organic_carbon variable
conti_var(df.Organic_carbon)
# EDA of Trihalomethanes variable
conti_var(df.Trihalomethanes)
# EDA of Turbidity variable
conti_var(df.Turbidity)

"""Handling outliers

In statistics, we have three measures of central tendency namely Mean, Median, and Mode. They help us describe the data.

Mean is the accurate measure to describe the data when we do not have any outliers present.

Median is used if there is an outlier in the dataset.

Mode is used if there is an outlier AND about ½ or more of the data is the same.

‘Mean’ is the only measure of central tendency that is affected by the outliers which in turn impacts Standard deviation.
"""

def remove_outliers(df, threshold=3):
    z_scores = stats.zscore(df)
    abs_z_scores = np.abs(z_scores)
    filtered_entries = (abs_z_scores < threshold).all(axis=1)
    return df[filtered_entries]

# remove outliers using threshold 3
df_out = remove_outliers(df)

# Print the DataFrame after removing outliers
print(df_out)

"""feature Selection"""

#Feature selection using random forest feature importance
#importing the libraries
from sklearn.ensemble import RandomForestClassifier

#initializing the model
ran = RandomForestClassifier()

#fitting the model
ran.fit(df_out.drop('Potability',axis=1),df_out.Potability)

plt.figure(figsize=(10,5))
sns.barplot(x=ran.feature_importances_,y=df_out.drop('Potability',axis=1).columns)
plt.show()

#splitting the data into input and output
x = df_out.drop(['Potability','Organic_carbon'],axis=1)
y = df_out.Potability

print('input shape={}, output shape={}'.format(x.shape,y.shape))

#Standard scalar is used to avoid scaling effect
#importing the libraries
from sklearn.preprocessing import StandardScaler

scalar = StandardScaler()

#fitting scalar model for input data
x = pd.DataFrame(scalar.fit_transform(x),columns=x.columns)

#splitting entire data into 80% train and 20% test
# importing the libraries
from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2,random_state=1)

print('Shape of Splitting:')
print('x_train={},y_train={},x_test={},y_test={}'.format(x_train.shape,y_train.shape,x_test.shape,y_test.shape))

"""Model Selection

"""

model = [LogisticRegression(), DecisionTreeClassifier(), GaussianNB(), RandomForestClassifier(),
        svm.LinearSVC(), XGBClassifier()]
trainAccuracy = list()
testAccuracy = list()
kfold = KFold(n_splits=10, random_state=7, shuffle=True)

for mdl in model:
    trainResult = cross_val_score(mdl, x_train, y_train, scoring='accuracy', cv=kfold)
    trainAccuracy.append(trainResult.mean())
    mdl.fit(x_train, y_train)
    y_pred = mdl.predict(x_test)
    testResult = metrics.accuracy_score(y_test, y_pred)
    testAccuracy.append(testResult)

print('The comparision\n')
modelScore = pd.DataFrame({'Model' : model, 'Train_Accuracy' : trainAccuracy, 
                           'Test_Accuracy' : testAccuracy})
modelScore

"""**RANDOM FOREST** **CLASSIFIER** """

print('Random Forest Classifier\n')
from sklearn.metrics import classification_report, plot_confusion_matrix, plot_roc_curve, accuracy_score
modelAccuracy = list()
Rfc = RandomForestClassifier()
pred_Rfc=Rfc.fit(x_train, y_train)

y_Rfc = Rfc.predict(x_test)
print(metrics.classification_report(y_test, y_Rfc))
print(modelAccuracy.append(metrics.accuracy_score(y_test, y_Rfc)))

sns.heatmap(confusion_matrix(y_test, y_Rfc), annot=True, fmt='d')
plt.show()
#plotting the ROC curve
print('ROC curve :')
plot_roc_curve(Rfc,x_test,y_test)
plt.plot([0,1],[0,1])
plt.show()

#accuracy score
#accuracy_score(y_test,pred_Rfc)

#checking for hyper parameters
Rfc.get_params().keys()

#hyper parameters
params = {'max_depth':[15,20,25],
          'min_samples_leaf':[10,20,30],
          'min_samples_split':[10,20,30],
          'n_estimators' : [200,250,300]
         }
#initializing the grid
grid_Rfc = GridSearchCV(estimator=Rfc,param_grid=params,cv=3,verbose=3,n_jobs=-1)

#fitting for test data
pred_Rfc = grid_Rfc.fit(x_train,y_train).predict(x_test)

#printing best score and parameters
print('Best score = {}\nBest params = {}'.format(grid_Rfc.best_score_,grid_Rfc.best_params_))

#printing the report
print('Report: \n',classification_report(y_test,pred_Rfc))

#confusion matrix
print('confusion matrix:')
plot_confusion_matrix(grid_Rfc,x_test,y_test,cmap='inferno')
plt.show()

#plotting the ROC curve
print('ROC curve :')
plot_roc_curve(grid_Rfc,x_test,y_test)
plt.plot([0,1],[0,1])
plt.show()

#accuracy score
acc_Rfc = accuracy_score(y_test,pred_Rfc)
print("accuracy score of the model",acc_Rfc)

"""# **XGB** **CLASSIFIER** """

print('XGB Classifier\n')
from sklearn.metrics import classification_report, plot_confusion_matrix, plot_roc_curve, accuracy_score
xgb = XGBClassifier()
pred_xgb=xgb.fit(x_train, y_train)

y_xgb = xgb.predict(x_test)
print(metrics.classification_report(y_test, y_xgb))
print(modelAccuracy.append(metrics.accuracy_score(y_test, y_xgb)))

sns.heatmap(confusion_matrix(y_test, y_xgb), annot=True, fmt='d')
plt.show()
#plotting the ROC curve
plot_roc_curve(xgb,x_test,y_test)
plt.plot([0,1],[0,1])
plt.show()


#accuracy score
#acc_xgb = accuracy_score(y_test,pred_xgb)

xgb.get_params().keys()

#hyper parameters
params = {'max_depth':[5,10,15],
          'learning_rate':[0.001,0.01,0.1],
          'n_estimators':[350,400,500]
         }
#initializing the grid
grid_xgb = GridSearchCV(estimator=xgb,param_grid=params,cv=3,verbose=3,n_jobs=-1)

#fitting for test data
pred_xgb = grid_xgb.fit(x_train,y_train).predict(x_test)

#printing best score and parameters
print('Best score = {}\nBest params = {}'.format(grid_xgb.best_score_,grid_xgb.best_params_))

#printing the report
print('Report: \n',classification_report(y_test,pred_xgb))

#confusion matrix
print('confusion matrix:')
plot_confusion_matrix(grid_xgb,x_test,y_test,cmap='inferno')
plt.show()

#plotting the ROC curve
print('ROC curve :')
plot_roc_curve(grid_xgb,x_test,y_test)
plt.plot([0,1],[0,1])
plt.show()

#accuracy score
acc_xgb = accuracy_score(y_test,pred_xgb)
print(acc_xgb)

